{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion completed for all TSV files in the folder.\n"
     ]
    }
   ],
   "source": [
    "from Scripts.Data.NFL_data_preprocessing import preprocess_nfl, open_all_tsv\n",
    "\n",
    "dataframes = open_all_tsv('Data/NFL/')\n",
    "\n",
    "dataframes = preprocess_nfl(dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of successfully converted dataframes: 554\n",
      "Number of failed conversions: 0\n"
     ]
    }
   ],
   "source": [
    "def prepare_data(dataframes, test_games):\n",
    "    X_train, Y_train, Y_train_noised = {}, {}, {}\n",
    "    X_test, Y_test, Y_test_noised = {}, {}, {}\n",
    "    num_success = 0\n",
    "    num_fail = 0\n",
    "\n",
    "    # Noise process parameters\n",
    "    N = 1000\n",
    "    gamma_min = 0.1\n",
    "    gamma_max = 0.9\n",
    "    gammas = np.linspace(gamma_max, gamma_min, N)\n",
    "\n",
    "    for df_name, df in dataframes.items():\n",
    "        # Skip the test game in the training set creation\n",
    "        if df_name in test_games:\n",
    "            continue\n",
    "\n",
    "        # Reset the index of the DataFrame if 'playerId' is an index\n",
    "        if 'playerId' in df.index.names:\n",
    "            df.reset_index('playerId', drop=True, inplace=True)\n",
    "\n",
    "        # Keep only numeric columns in the dataframe\n",
    "        df = df.select_dtypes(include=[np.number])\n",
    "\n",
    "        # Apply the noise process to the dataframe\n",
    "        noisy_df = np.copy(df.values)\n",
    "        for t in range(1, len(df)):\n",
    "            k = min(t, N-1)  # Ensure not to exceed the number of defined gammas\n",
    "            gamma = gammas[k]\n",
    "            Z_t = np.random.normal(0, 1, size=df.iloc[t].shape)\n",
    "            noisy_df[t] = gamma * df.iloc[t - 1] + np.sqrt(1 - gamma**2) * Z_t\n",
    "\n",
    "        # Calculate the difference between the original and noisy trajectories\n",
    "        y = df.values - noisy_df\n",
    "\n",
    "        try:\n",
    "            # Reshape the data to the format (number_frames, number_players, number_features)\n",
    "            num_frames = int(df.shape[0] / 23)\n",
    "            num_features = df.shape[1]\n",
    "            x = df.values.reshape(num_frames, 23, num_features)\n",
    "            y = y.reshape(num_frames, 23, num_features)\n",
    "\n",
    "            # Remove one frame if the number of frames is odd\n",
    "            if num_frames % 2 != 0:\n",
    "                x = x[:-1]  # Remove the last frame\n",
    "                y = y[:-1]  # Remove the last frame\n",
    "\n",
    "            # Split the data into two equal parts\n",
    "            split_index = int(num_frames * 0.5)\n",
    "\n",
    "            x, y_target = x[:split_index], x[split_index:]\n",
    "            y_noised, y_target_noised = y[:split_index], y[split_index:]\n",
    "\n",
    "            # Append to respective dictionaries\n",
    "            X_train[df_name] = torch.tensor(x, dtype=torch.float32)\n",
    "            Y_train[df_name] = torch.tensor(y_target, dtype=torch.float32)\n",
    "            Y_train_noised[df_name] = torch.tensor(y_target_noised, dtype=torch.float32)\n",
    "            num_success += 1\n",
    "        except ValueError:\n",
    "            print(f\"Failed to reshape dataframe '{df_name}'\")\n",
    "            num_fail += 1\n",
    "\n",
    "    print(f\"Number of successfully converted dataframes: {num_success}\")\n",
    "    print(f\"Number of failed conversions: {num_fail}\")\n",
    "\n",
    "    # Prepare the test set\n",
    "    for test_game in test_games:\n",
    "        test_df = dataframes[test_game]\n",
    "\n",
    "        if 'playerId' in test_df.index.names:\n",
    "            test_df.reset_index('playerId', drop=True, inplace=True)\n",
    "        test_df = test_df.select_dtypes(include=[np.number])\n",
    "        noisy_df = np.copy(test_df.values)\n",
    "        for t in range(1, len(test_df)):\n",
    "            k = min(t, N-1)\n",
    "            gamma = gammas[k]\n",
    "            Z_t = np.random.normal(0, 1, size=test_df.iloc[t].shape)\n",
    "            noisy_df[t] = gamma * test_df.iloc[t - 1] + np.sqrt(1 - gamma**2) * Z_t\n",
    "\n",
    "        y = test_df.values - noisy_df\n",
    "        num_frames = int(test_df.shape[0] / 23)\n",
    "        num_features = test_df.shape[1]\n",
    "        x = test_df.values.reshape(num_frames, 23, num_features)\n",
    "        y = y.reshape(num_frames, 23, num_features)\n",
    "\n",
    "        # Remove one frame if the number of frames is odd\n",
    "        if num_frames % 2 != 0:\n",
    "            x = x[:-1]  # Remove the last frame\n",
    "            y = y[:-1]  # Remove the last frame\n",
    "\n",
    "        # Split the data into two equal parts\n",
    "        split_index = int(num_frames * 0.5)\n",
    "\n",
    "        x, y_target = x[:split_index], x[split_index:]\n",
    "        y_noised, y_target_noised = y[:split_index], y[split_index:]\n",
    "\n",
    "        # Append to respective dictionaries\n",
    "        X_test[test_game] = torch.tensor(x, dtype=torch.float32)\n",
    "        Y_test[test_game] = torch.tensor(y_target, dtype=torch.float32)\n",
    "        Y_test_noised[test_game] = torch.tensor(y_target_noised, dtype=torch.float32)\n",
    "\n",
    "    return X_train, Y_train, Y_train_noised, X_test, Y_test, Y_test_noised\n",
    "\n",
    "\n",
    "\n",
    "test_games = ['2019_WAS_2019090806_193', '2019_WAS_2019090806_1117', '2019_WAS_2019092907_2823', '2019_WAS_2019100609_431', '2019_WAS_2019111707_3624', '2019_WAS_2019120803_3729', '2019_WAS_2019121508_700']\n",
    "\n",
    "# Assume `dataframes` is your preprocessed data\n",
    "X_train, Y_train, Y_train_noised, X_test, Y_test, Y_test_noised = prepare_data(dataframes, test_games)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save\n",
    "with open('Data/nfl_train_test_data_diff.pkl', 'wb') as f:\n",
    "    pickle.dump({'X_train': X_train, 'Y_train': Y_train, 'Y_train_noised':Y_train_noised, 'X_test': X_test, 'Y_test': Y_test, 'Y_test_noised':Y_test_noised}, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "# Load\n",
    "with open('Data/nfl_train_test_data_diff.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "    X_train = data['X_train']\n",
    "    Y_train = data['Y_train']\n",
    "    Y_train_noised = data['Y_train_noised']\n",
    "    X_test = data['X_test']\n",
    "    Y_test = data['Y_test']\n",
    "    Y_test_noised = data['Y_test_noised']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Initialize the dictionaries for the normalized data\n",
    "X_train_normalized = {}\n",
    "Y_train_normalized = {}\n",
    "Y_train_noised_normalized = {}\n",
    "X_test_normalized = {}\n",
    "Y_test_normalized = {}\n",
    "Y_test_noised_normalized = {}\n",
    "\n",
    "# Initialize the scalers\n",
    "scaler_x = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "scaler_y_noised = StandardScaler()\n",
    "\n",
    "# Normalize the training data\n",
    "for game, x in X_train.items():\n",
    "    y = Y_train[game]\n",
    "    y_noised = Y_train_noised[game]\n",
    "\n",
    "    # Flatten the tensors along the frame and player dimensions\n",
    "    x_flattened = x.view(x.shape[0] * x.shape[1], -1).numpy()\n",
    "    y_flattened = y.view(y.shape[0] * y.shape[1], -1).numpy()\n",
    "    y_noised_flattened = y_noised.view(y_noised.shape[0] * y_noised.shape[1], -1).numpy()\n",
    "\n",
    "    # Fit the scalers to the flattened tensors and transform\n",
    "    x_normalized_np = scaler_x.fit_transform(x_flattened)\n",
    "    y_normalized_np = scaler_y.fit_transform(y_flattened)\n",
    "    y_noised_normalized_np = scaler_y_noised.fit_transform(y_noised_flattened)\n",
    "\n",
    "    # Convert the normalized arrays back to tensors and reshape to original shape\n",
    "    x_normalized = torch.tensor(x_normalized_np, dtype=torch.float32).view(x.shape)\n",
    "    y_normalized = torch.tensor(y_normalized_np, dtype=torch.float32).view(y.shape)\n",
    "    y_noised_normalized = torch.tensor(y_noised_normalized_np, dtype=torch.float32).view(y_noised.shape)\n",
    "\n",
    "    # Append to the dictionaries\n",
    "    X_train_normalized[game] = x_normalized\n",
    "    Y_train_normalized[game] = y_normalized\n",
    "    Y_train_noised_normalized[game] = y_noised_normalized\n",
    "\n",
    "# Normalize the testing data\n",
    "for game, x in X_test.items():\n",
    "    y = Y_test[game]\n",
    "    y_noised = Y_test_noised[game]\n",
    "\n",
    "    # Flatten the tensors along the frame and player dimensions\n",
    "    x_flattened = x.view(x.shape[0] * x.shape[1], -1).numpy()\n",
    "    y_flattened = y.view(y.shape[0] * y.shape[1], -1).numpy()\n",
    "    y_noised_flattened = y_noised.view(y_noised.shape[0] * y_noised.shape[1], -1).numpy()\n",
    "\n",
    "    # Transform the flattened tensors using the fitted scalers\n",
    "    x_normalized_np = scaler_x.fit_transform(x_flattened)\n",
    "    y_normalized_np = scaler_y.fit_transform(y_flattened)\n",
    "    y_noised_normalized_np = scaler_y_noised.fit_transform(y_noised_flattened)\n",
    "\n",
    "    # Convert the normalized arrays back to tensors and reshape to original shape\n",
    "    x_normalized = torch.tensor(x_normalized_np, dtype=torch.float32).view(x.shape)\n",
    "    y_normalized = torch.tensor(y_normalized_np, dtype=torch.float32).view(y.shape)\n",
    "    y_noised_normalized = torch.tensor(y_noised_normalized_np, dtype=torch.float32).view(y_noised.shape)\n",
    "\n",
    "    # Append to the dictionaries\n",
    "    X_test_normalized[game] = x_normalized\n",
    "    Y_test_normalized[game] = y_normalized\n",
    "    Y_test_noised_normalized[game] = y_noised_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Scripts.Results.Metrics.Evaluation_Metrics import train_diff\n",
    "from Scripts.Models.SocialTransformer4 import DiffusionTransformer\n",
    "\n",
    "input_size = list(X_train_normalized.values())[0].shape[2]\n",
    "output_size = list(Y_train_normalized.values())[0].shape[2]\n",
    "hidden_size = 256\n",
    "num_layers = 2\n",
    "nhead = 6\n",
    "dropout = 0.1\n",
    "max_len = 5000\n",
    "model = DiffusionTransformer(d_model=input_size, nhead=nhead, num_encoder_layers=num_layers, d_ff=hidden_size, dropout=dropout, max_len=max_len)\n",
    "\n",
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 0.5046, Test Loss: 0.0698,  Time: 104.4583s\n",
      "Epoch 2/10, Train Loss: 0.0869, Test Loss: 0.0385,  Time: 99.2904s\n",
      "Epoch 3/10, Train Loss: 0.0612, Test Loss: 0.0339,  Time: 100.9709s\n",
      "Epoch 4/10, Train Loss: 0.0543, Test Loss: 0.0311,  Time: 102.5366s\n",
      "Epoch 5/10, Train Loss: 0.0510, Test Loss: 0.0308,  Time: 100.4723s\n",
      "Epoch 6/10, Train Loss: 0.0492, Test Loss: 0.0305,  Time: 101.0724s\n",
      "Epoch 7/10, Train Loss: 0.0479, Test Loss: 0.0303,  Time: 102.2808s\n",
      "Epoch 8/10, Train Loss: 0.0472, Test Loss: 0.0303,  Time: 100.5009s\n",
      "Epoch 9/10, Train Loss: 0.0466, Test Loss: 0.0303,  Time: 100.9834s\n",
      "Epoch 10/10, Train Loss: 0.0462, Test Loss: 0.0303,  Time: 102.4550s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DiffusionTransformer(\n",
       "  (pos_encoding): RotaryPositionalEncoding(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (social_encoder): SocialEncoder(\n",
       "    (linear_q): Linear(in_features=12, out_features=12, bias=True)\n",
       "    (linear_k): Linear(in_features=12, out_features=12, bias=True)\n",
       "    (linear_v): Linear(in_features=12, out_features=12, bias=True)\n",
       "    (linear_out): Linear(in_features=12, out_features=12, bias=True)\n",
       "    (attention): MultiHeadAttention(\n",
       "      (linear_q): Linear(in_features=12, out_features=12, bias=True)\n",
       "      (linear_k): Linear(in_features=12, out_features=12, bias=True)\n",
       "      (linear_v): Linear(in_features=12, out_features=12, bias=True)\n",
       "      (linear_out): Linear(in_features=12, out_features=12, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (feedforward): FeedForward(\n",
       "      (linear1): Linear(in_features=12, out_features=48, bias=True)\n",
       "      (linear2): Linear(in_features=48, out_features=12, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (layernorm1): LayerNorm((12,), eps=1e-05, elementwise_affine=True)\n",
       "    (layernorm2): LayerNorm((12,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (ddpm): DDPM()\n",
       "  (resnet_transformer): ResNetTransformer(\n",
       "    (encoder_layers): ModuleList(\n",
       "      (0-1): 2 x TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=12, out_features=12, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=12, out_features=12, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (norm1): LayerNorm((12,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (decoder_layers): ModuleList(\n",
       "      (0-1): 2 x TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=12, out_features=12, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=12, out_features=12, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=12, out_features=12, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (norm1): LayerNorm((12,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((12,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (final_layer): Linear(in_features=12, out_features=12, bias=True)\n",
       "  (cnn_decoder): CNNDecoder(\n",
       "    (conv1): Conv1d(12, 12, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (conv2): Conv1d(12, 12, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (conv3): Conv1d(12, 12, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  )\n",
       "  (output_norm): LayerNorm((12,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import time\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "from Scripts.Results.Metrics.Evaluation_Metrics import train_diff\n",
    "from Scripts.Models.SocialTransformer4 import DiffusionTransformer\n",
    "\n",
    "input_size = list(X_train_normalized.values())[0].shape[2]\n",
    "output_size = list(Y_train_normalized.values())[0].shape[2]\n",
    "hidden_size = 256\n",
    "num_layers = 2\n",
    "nhead = 6\n",
    "dropout = 0.1\n",
    "max_len = 5000\n",
    "model = DiffusionTransformer(d_model=input_size, nhead=nhead, num_encoder_layers=num_layers, d_ff=hidden_size, dropout=dropout, max_len=max_len)\n",
    "\n",
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "epochs = 10\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = ReduceLROnPlateau(optimizer, factor=0.5, patience=3, verbose=True)\n",
    "\n",
    "model.train()\n",
    "best_val_loss = float('inf')\n",
    "no_improvement = 0\n",
    "patience = 3\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    start_time = time.time()\n",
    "    train_loss = 0.0\n",
    "    for df_name, x in X_train_normalized.items():\n",
    "        y = Y_train_normalized[df_name]\n",
    "        y_noised = Y_train_noised_normalized[df_name]\n",
    "        for i in range(0, len(x), batch_size):\n",
    "            optimizer.zero_grad()\n",
    "            batch_x = x[i:i+batch_size]\n",
    "            batch_y = y[i:i+batch_size]\n",
    "            batch_y_noised = y_noised[i:i+batch_size]\n",
    "            output = model(batch_x, batch_y_noised)\n",
    "            output = batch_y+output\n",
    "\n",
    "            loss = criterion(output, batch_y_noised)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "    train_loss /= len(X_train)\n",
    "\n",
    "    # Evaluation on the test set\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for test_game, x in X_test_normalized.items():\n",
    "            x = X_test_normalized[test_game]\n",
    "            y = Y_test_normalized[test_game]\n",
    "            y_noised = Y_test_noised_normalized[test_game]\n",
    "            for i in range(0, len(x), batch_size):\n",
    "                batch_x = x[i:i+batch_size]\n",
    "                batch_y = y[i:i+batch_size]\n",
    "                batch_y_noised = y_noised[i:i+batch_size]\n",
    "                output = model(batch_x, batch_y_noised)\n",
    "                loss = criterion(output+batch_y, batch_y_noised)\n",
    "\n",
    "                test_loss += loss.item()\n",
    "\n",
    "        test_loss /= len(X_test)\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f},  Time: {time.time() - start_time:.4f}s\")\n",
    "\n",
    "    if test_loss < best_val_loss:\n",
    "        best_val_loss = test_loss\n",
    "        no_improvement = 0\n",
    "        torch.save(model.state_dict(), './Visualization/Results/socialdiff_model3.pt')\n",
    "    else:\n",
    "        no_improvement += 1\n",
    "        if no_improvement >= patience:\n",
    "            print(f'Early stopping at epoch {epoch+1}')\n",
    "            break\n",
    "\n",
    "    scheduler.step(test_loss)\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0058\n",
      "Mean Squared Error: 0.0056\n",
      "R^2 Score: 0.9111\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Test the model on the test set\n",
    "model.load_state_dict(torch.load('./Visualization/Results/socialdiff_model3.pt'))\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "criterion = nn.MSELoss()\n",
    "with torch.no_grad():\n",
    "    for test_game, x_test in X_test_normalized.items():\n",
    "        y_test = Y_test_normalized[test_game]\n",
    "        y_test_noised = Y_test_noised_normalized[test_game]\n",
    "        output = model(x_test, y_test_noised)\n",
    "        loss = criterion(output+y_test, y_test_noised)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "test_loss /= len(X_test)\n",
    "print(f'Test Loss: {test_loss:.4f}')\n",
    "\n",
    "# Analyze the predictions on the test set\n",
    "predicted_noises = []\n",
    "actual_noises = []\n",
    "with torch.no_grad():\n",
    "    for test_game, x_test in X_test_normalized.items():\n",
    "        y_test = Y_test_normalized[test_game]\n",
    "        y_test_noised = Y_test_noised_normalized[test_game]\n",
    "        output = model(x_test, y_test_noised)\n",
    "        predicted_noise = output+y_test\n",
    "        predicted_noises.append(predicted_noise.detach().numpy().reshape(-1, output.shape[-1]))\n",
    "        actual_noises.append(y_test_noised.numpy().reshape(-1, y_test.shape[-1]))\n",
    "\n",
    "# Flatten the predicted noises and actual noises for analysis\n",
    "predicted_noises = np.concatenate(predicted_noises)\n",
    "actual_noises = np.concatenate(actual_noises)\n",
    "\n",
    "# Calculate the mean squared error and R^2 score\n",
    "mse = mean_squared_error(actual_noises, predicted_noises)\n",
    "r2 = r2_score(actual_noises, predicted_noises)\n",
    "print(f'Mean Squared Error: {mse:.4f}')\n",
    "print(f'R^2 Score: {r2:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from Scripts.Results.Metrics.Evaluation_Metrics import min_ade23, min_fde23, reverse_diffusion_process\n",
    "\n",
    "\n",
    "num_samples = 1000\n",
    "pred_trajs_list = []\n",
    "with torch.no_grad():\n",
    "    for test_game, x_test in X_test_normalized.items():\n",
    "        pred_trajs = []\n",
    "        y_test = Y_test_normalized[test_game]\n",
    "        y_test_noised = Y_test_noised_normalized[test_game]\n",
    "        output = model(x_test, y_test_noised)\n",
    "        noise_predictions = output.detach().cpu().numpy()\n",
    "        for _ in range(num_samples):\n",
    "            x_pred = reverse_diffusion_process(model, x_test, noise_predictions)\n",
    "            pred_trajs.append(x_pred.detach().cpu().numpy())\n",
    "        pred_trajs_list.append(pred_trajs)\n",
    "\n",
    "min_ade23_list = []\n",
    "min_fde23_list = []\n",
    "for pred_trajs, gt_traj in zip(pred_trajs_list, X_test_normalized.values()):\n",
    "    gt_traj = gt_traj.detach().cpu().numpy()\n",
    "    min_ade23_ = min_ade23(pred_trajs, gt_traj)\n",
    "    min_fde23_ = min_fde23(pred_trajs, gt_traj)\n",
    "    min_ade23_list.append(min_ade23_)\n",
    "    min_fde23_list.append(min_fde23_)\n",
    "\n",
    "avg_min_ade23 = np.mean(min_ade23_list)\n",
    "avg_min_fde23 = np.mean(min_fde23_list)\n",
    "\n",
    "print(f'minADE23: {avg_min_ade23:.4f}, minFDE23: {avg_min_fde23:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
